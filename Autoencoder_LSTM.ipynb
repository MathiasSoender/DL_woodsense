{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/sensor1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       sensor_id                  timestamp  temperature  humidity  \\\n",
       "0              1  2020-08-28 03:00:00+00:00    15.012970     77.00   \n",
       "1              1  2020-08-28 04:00:00+00:00    15.198558     77.00   \n",
       "2              1  2020-08-28 05:00:00+00:00    15.384146     77.00   \n",
       "3              1  2020-08-28 06:00:00+00:00    15.569734     77.00   \n",
       "4              1  2020-08-28 07:00:00+00:00    15.755322     77.00   \n",
       "...          ...                        ...          ...       ...   \n",
       "57967         42  2020-10-20 19:00:00+00:00    10.695000     99.99   \n",
       "57968         42  2020-10-20 20:00:00+00:00    10.660000     99.99   \n",
       "57969         42  2020-10-20 21:00:00+00:00    10.666667     99.99   \n",
       "57970         42  2020-10-20 22:00:00+00:00    10.673333     99.99   \n",
       "57971         42  2020-10-20 23:00:00+00:00    10.680000     99.99   \n",
       "\n",
       "             ohms   moisture  weather_humidity  weather_pressure  \\\n",
       "0      270.067017  12.990156         95.579013       1004.827315   \n",
       "1      261.323128  13.038244         96.114617       1004.332653   \n",
       "2      252.579239  13.086331         95.666685       1003.678711   \n",
       "3      243.835350  13.134418         94.448831       1003.407445   \n",
       "4      235.091461  13.182506         93.943871       1003.311881   \n",
       "...           ...        ...               ...               ...   \n",
       "57967   55.961068  15.403181         83.363973       1002.234081   \n",
       "57968   56.017153  15.401460         89.845917       1002.017034   \n",
       "57969   55.524990  15.416776         92.324956       1001.807850   \n",
       "57970   55.032826  15.432091         93.548737       1001.611697   \n",
       "57971   54.540663  15.447407         94.581768       1001.269094   \n",
       "\n",
       "       weather_temp_dew  weather_temp_dry  weather_wind_dir  \\\n",
       "0             11.475756         12.131467        108.966365   \n",
       "1             12.136401         12.751486        103.050999   \n",
       "2             12.646634         13.377194        102.429338   \n",
       "3             13.056790         13.834935        111.662148   \n",
       "4             13.650739         14.700486         88.541827   \n",
       "...                 ...               ...               ...   \n",
       "57967          7.042912          9.740160        191.395958   \n",
       "57968          7.713235          9.304126        191.618384   \n",
       "57969          8.107616          9.218550        188.959264   \n",
       "57970          8.526925          9.522056        191.684353   \n",
       "57971          9.127066          9.842974        205.012215   \n",
       "\n",
       "       weather_wind_speed  weather_wind_max  weather_wind_min  \\\n",
       "0                1.825696          2.818346               NaN   \n",
       "1                2.153497          3.074299               NaN   \n",
       "2                1.645717          2.843965               NaN   \n",
       "3                2.000634          3.346310               NaN   \n",
       "4                1.934695          3.406582               NaN   \n",
       "...                   ...               ...               ...   \n",
       "57967            2.868811          5.950202               NaN   \n",
       "57968            2.302741          4.824224               NaN   \n",
       "57969            2.140578          4.475191               NaN   \n",
       "57970            2.046183          4.293633               NaN   \n",
       "57971            2.100424          4.360580               NaN   \n",
       "\n",
       "       weather_precip_past10min  \n",
       "0                      0.000000  \n",
       "1                      0.000000  \n",
       "2                      0.000000  \n",
       "3                      0.000000  \n",
       "4                      0.000000  \n",
       "...                         ...  \n",
       "57967                  0.068418  \n",
       "57968                  0.031582  \n",
       "57969                  0.000000  \n",
       "57970                  0.000000  \n",
       "57971                  0.000000  \n",
       "\n",
       "[57972 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor_id</th>\n      <th>timestamp</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>ohms</th>\n      <th>moisture</th>\n      <th>weather_humidity</th>\n      <th>weather_pressure</th>\n      <th>weather_temp_dew</th>\n      <th>weather_temp_dry</th>\n      <th>weather_wind_dir</th>\n      <th>weather_wind_speed</th>\n      <th>weather_wind_max</th>\n      <th>weather_wind_min</th>\n      <th>weather_precip_past10min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-08-28 03:00:00+00:00</td>\n      <td>15.012970</td>\n      <td>77.00</td>\n      <td>270.067017</td>\n      <td>12.990156</td>\n      <td>95.579013</td>\n      <td>1004.827315</td>\n      <td>11.475756</td>\n      <td>12.131467</td>\n      <td>108.966365</td>\n      <td>1.825696</td>\n      <td>2.818346</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-08-28 04:00:00+00:00</td>\n      <td>15.198558</td>\n      <td>77.00</td>\n      <td>261.323128</td>\n      <td>13.038244</td>\n      <td>96.114617</td>\n      <td>1004.332653</td>\n      <td>12.136401</td>\n      <td>12.751486</td>\n      <td>103.050999</td>\n      <td>2.153497</td>\n      <td>3.074299</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2020-08-28 05:00:00+00:00</td>\n      <td>15.384146</td>\n      <td>77.00</td>\n      <td>252.579239</td>\n      <td>13.086331</td>\n      <td>95.666685</td>\n      <td>1003.678711</td>\n      <td>12.646634</td>\n      <td>13.377194</td>\n      <td>102.429338</td>\n      <td>1.645717</td>\n      <td>2.843965</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2020-08-28 06:00:00+00:00</td>\n      <td>15.569734</td>\n      <td>77.00</td>\n      <td>243.835350</td>\n      <td>13.134418</td>\n      <td>94.448831</td>\n      <td>1003.407445</td>\n      <td>13.056790</td>\n      <td>13.834935</td>\n      <td>111.662148</td>\n      <td>2.000634</td>\n      <td>3.346310</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2020-08-28 07:00:00+00:00</td>\n      <td>15.755322</td>\n      <td>77.00</td>\n      <td>235.091461</td>\n      <td>13.182506</td>\n      <td>93.943871</td>\n      <td>1003.311881</td>\n      <td>13.650739</td>\n      <td>14.700486</td>\n      <td>88.541827</td>\n      <td>1.934695</td>\n      <td>3.406582</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57967</th>\n      <td>42</td>\n      <td>2020-10-20 19:00:00+00:00</td>\n      <td>10.695000</td>\n      <td>99.99</td>\n      <td>55.961068</td>\n      <td>15.403181</td>\n      <td>83.363973</td>\n      <td>1002.234081</td>\n      <td>7.042912</td>\n      <td>9.740160</td>\n      <td>191.395958</td>\n      <td>2.868811</td>\n      <td>5.950202</td>\n      <td>NaN</td>\n      <td>0.068418</td>\n    </tr>\n    <tr>\n      <th>57968</th>\n      <td>42</td>\n      <td>2020-10-20 20:00:00+00:00</td>\n      <td>10.660000</td>\n      <td>99.99</td>\n      <td>56.017153</td>\n      <td>15.401460</td>\n      <td>89.845917</td>\n      <td>1002.017034</td>\n      <td>7.713235</td>\n      <td>9.304126</td>\n      <td>191.618384</td>\n      <td>2.302741</td>\n      <td>4.824224</td>\n      <td>NaN</td>\n      <td>0.031582</td>\n    </tr>\n    <tr>\n      <th>57969</th>\n      <td>42</td>\n      <td>2020-10-20 21:00:00+00:00</td>\n      <td>10.666667</td>\n      <td>99.99</td>\n      <td>55.524990</td>\n      <td>15.416776</td>\n      <td>92.324956</td>\n      <td>1001.807850</td>\n      <td>8.107616</td>\n      <td>9.218550</td>\n      <td>188.959264</td>\n      <td>2.140578</td>\n      <td>4.475191</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>57970</th>\n      <td>42</td>\n      <td>2020-10-20 22:00:00+00:00</td>\n      <td>10.673333</td>\n      <td>99.99</td>\n      <td>55.032826</td>\n      <td>15.432091</td>\n      <td>93.548737</td>\n      <td>1001.611697</td>\n      <td>8.526925</td>\n      <td>9.522056</td>\n      <td>191.684353</td>\n      <td>2.046183</td>\n      <td>4.293633</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>57971</th>\n      <td>42</td>\n      <td>2020-10-20 23:00:00+00:00</td>\n      <td>10.680000</td>\n      <td>99.99</td>\n      <td>54.540663</td>\n      <td>15.447407</td>\n      <td>94.581768</td>\n      <td>1001.269094</td>\n      <td>9.127066</td>\n      <td>9.842974</td>\n      <td>205.012215</td>\n      <td>2.100424</td>\n      <td>4.360580</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>57972 rows Ã— 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(df, test_split = 0.2, val_split = 0.2, RANDOM_SEED = 42):\n",
    "    \n",
    "    idx_train, idx_test = train_test_split([i for i in range(1,43)], test_size=test_split, random_state = RANDOM_SEED)\n",
    "    idx_only_train, idx_val = train_test_split(idx_train, test_size=val_split, random_state = RANDOM_SEED)\n",
    "    \n",
    "    df['Train'] = False\n",
    "    df['Validation'] = False\n",
    "    df['Test'] = False\n",
    "    \n",
    "    df.loc[df['sensor_id'].isin(idx_train), 'Train'] = True\n",
    "    df.loc[df['sensor_id'].isin(idx_test), 'Test'] = True\n",
    "    df.loc[df['sensor_id'].isin(idx_val), 'Validation'] = True\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "def set_index(df):\n",
    "    df['idx']=0\n",
    "    for idx, grp in enumerate(df.groupby('sensor_id')):\n",
    "        df.loc[df.sensor_id == grp[0], \"idx\"] = idx\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class data(Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_csv, test, list_features, fixed_points = False):\n",
    "        super(data).__init__()\n",
    "        df = pd.read_csv(path_to_csv)\n",
    "        df = split_train_test_val(df)\n",
    "        \n",
    "        if test:\n",
    "            self.df = df[df['Test']==True].reset_index()\n",
    "            del df\n",
    "            set_index(self.df)\n",
    "\n",
    "        else:\n",
    "            self.df = df[df['Train']==True].reset_index()\n",
    "            del df\n",
    "            set_index(self.df)\n",
    "\n",
    "        self.fixed_points = fixed_points\n",
    "        self.list_features = list_features\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.fixed_points:\n",
    "            nb_point=200\n",
    "            start = np.random.randint(0,len(self.df[self.df['idx']==index]) - nb_point +1)\n",
    "            _input = torch.from_numpy(np.array(self.df[self.df['idx']==index][self.list_features][start:start + nb_point]).transpose())[:,:-1]\n",
    "            target = torch.from_numpy(np.array(self.df[self.df['idx']==index][self.list_features][start:start + nb_point]).transpose())[:,1:]\n",
    "            \n",
    "            return _input, target\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            _input = torch.from_numpy(np.array(self.df[self.df['idx']==index][self.list_features]).transpose())[:,:-1]\n",
    "            target = torch.from_numpy(np.array(self.df[self.df['idx']==index][self.list_features]).transpose())[:,1:]\n",
    "            \n",
    "            return _input, target\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df.groupby('sensor_id'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data('Data/sensor1.csv', test = False, list_features = ['humidity'], fixed_points=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train |  torch.Size([1, 1, 1292]) | tensor([[[77.0000, 77.0000, 77.0000,  ..., 69.6000, 69.8000, 70.0000]]],\n       dtype=torch.float64)\nTest |  torch.Size([1, 1, 1292]) | tensor([[[77.0000, 77.0000, 77.0000,  ..., 69.4000, 69.6000, 69.8000]]],\n       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Shape : [Batch, Features, Time Steps]\n",
    "\n",
    "test, train = next(iter(loader))\n",
    "print(\"Train | \", train.shape, \"|\", train)\n",
    "print(\"Test | \", test.shape, \"|\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1, 1292])\ntorch.Size([1292, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # input: array-like of shape (n_samples, n_features)\n",
    "\n",
    "print(train.shape)\n",
    "train = train.permute(0,2,1)\n",
    "train = torch.squeeze(train, 0)\n",
    "print(train.shape)\n",
    "\n",
    "test = test.permute(0,2,1)\n",
    "test = torch.squeeze(test, 0)\n",
    "\n",
    "# Fit to data to range 0 - 1, then transform it.\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(train)\n",
    "X_test = scaler.fit_transform(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.unsqueeze(torch.from_numpy(X_train), 0)\n",
    "X_test = torch.unsqueeze(torch.from_numpy(X_test), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Autoencoder(\n  (encoder): Sequential(\n    (0): LSTM(1292, 400)\n    (1): ReLU(inplace=True)\n    (2): LSTM(400, 16)\n    (3): ReLU(inplace=True)\n  )\n  (decoder): Sequential(\n    (0): LSTM(16, 400)\n    (1): ReLU(inplace=True)\n    (2): LSTM(400, 1292)\n    (3): ReLU(inplace=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "\n",
    "        input_size = 1292\n",
    "        latent_1 = 400\n",
    "        bottleneck = 16\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.LSTM(input_size, latent_1),\n",
    "            nn.ReLU(True),\n",
    "            nn.LSTM(latent_1,bottleneck),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(             \n",
    "            nn.LSTM(bottleneck,latent_1),\n",
    "            nn.ReLU(True),\n",
    "            nn.LSTM(latent_1,input_size),\n",
    "            nn.ReLU(True))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    model = Autoencoder()\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, val_dataset, n_epochs):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.L1Loss(reduction='sum')\n",
    "    history = dict(train=[], val=[])\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model = model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        for seq_true in train_dataset:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            seq_pred = model(seq_true)\n",
    "            loss = criterion(seq_pred, seq_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        val_losses = []\n",
    "        model = model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for seq_true in val_dataset:\n",
    "\n",
    "                seq_true = seq_true\n",
    "                seq_pred = model(seq_true)\n",
    "                loss = criterion(seq_pred, seq_true)\n",
    "                val_losses.append(loss.item())\n",
    "            \n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        history['train'].append(train_loss)\n",
    "        history['val'].append(val_loss)\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-0066b97e54dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-f11eb644f9fc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, n_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mseq_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8b09435174c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m             nn.ReLU(True))\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    174\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m    175\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "model, history = train_model(model, X_train, X_test, n_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8f45e4997e9699ec145c2f5ae8a0ce7fd5ec7dd7e942db307b6ed1b1b778c9d2"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}